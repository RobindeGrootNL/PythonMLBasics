{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Python Exercise 2.2: Regularized Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Coursera_MachineLearningPython_ex2.zip', 'ex2data1.txt', 'ex2data2.txt', 'ex2_part_1.ipynb', 'Ex2_part_2_reg.ipynb', 'Old stuff']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np # linear algebra\n",
    "from numpy import loadtxt, where\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data plotting\n",
    "import numpy.matlib\n",
    "from scipy.stats import logistic # sigmoid function\n",
    "import scipy.optimize as opt\n",
    "from sklearn.preprocessing import PolynomialFeatures # import function to add polynomial features\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../ex2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This file  contains code that helps you get started on the exercise. You will need to complete functions in this exericse. The instructions can be found in this notebook, which will load the program as you complete the exercises. If you need to change the code in a certain section, it will be clearly indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.array(pd.read_csv('ex2data2.txt', sep=\",\", header=None)) # import data\n",
    "X = data[:,0:2].reshape((118,2))   # initialize data X in 118x2 array\n",
    "y = data[:,2].reshape((118,1))     # initialize data y in 118x1 array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy your plotData section here, but change plt.xlabel('Exam 1 score') to plt.xlabel('Microchip Test 1') and change plt.ylabel('Profit in 10,000s') to plt.ylabel('Microchip Test 2'). Also add plt.legend(['y=1'], ['y=2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined function because python does not have a find() that Matlab has\n",
    "def indices(a, func):\n",
    "    return [i for (i, val) in enumerate(a) if func(val)]\n",
    "\n",
    "def plotData(x,y):                               # define function to reference later\n",
    "    ## Your code\n",
    "\n",
    "    # Correct answer:\n",
    "    pos = indices(y, lambda y: y > 0)  # filter the positive results (y = 1)\n",
    "    neg = indices(y, lambda y: y == 0) # filter the negative results (y = 0)\n",
    "\n",
    "    plt.scatter(X[pos,0], X[pos,1], color = 'k', marker = '+') # set plotting parameters (colour=red, marker=cross)\n",
    "    plt.scatter(X[neg,0], X[neg,1], color = 'y', marker = 'o') # set plotting parameters (colour=red, marker=cross)\n",
    "    plt.xlabel('Microchip Test 1')  # set the x-axis label\n",
    "    plt.ylabel('Microchip Test 2')             # set the y-axis label\n",
    "    plt.legend(['y=1', 'y=0'])\n",
    "    plt.show()                                   # plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting data\n",
    "plotData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature mapping\n",
    "This function maps the two input features to quadratic features used in the regularization exercise. It returns a new feature array with more features, comprising of $X1 = X[:,0]; X2 = X[:,1]$\n",
    "$X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2$, etc.. depending on the number of degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapFeature(X):\n",
    "    degree = 6 # number of polynomial degrees\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X = poly.fit_transform(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete this costFunctionReg file:\n",
    "Compute cost computes and gradient for logistic regression.\n",
    "\n",
    "Instructions: Compute the cost of a particular choice of theta. Compute the partial derivatives to calculate grad, which should have the same dimensions as theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some useful values\n",
    "m = len(y) # number of training examples\n",
    "\n",
    "def costFunctionReg(theta, X, y, lambda_var):        # define function to reference later\n",
    "    grad = np.zeros((theta.shape)) # initiate grad as an array\n",
    "    reg = 0 # initiate reg value\n",
    "    ## Your code\n",
    "    \n",
    "    # correct answer\n",
    "    z = np.dot(X,theta) # X * theta\n",
    "    h = logistic.cdf(z) # sigmoid(X*theta)\n",
    "    \n",
    "    n = X.shape[1] # define how many thetas need to be regularized\n",
    "    \n",
    "    for j in range(1,n): # calculate the regularization value\n",
    "        reg = reg + lambda_var/(2*m)*theta[j]**2 # regularization piece of \n",
    "                                                # function\n",
    "        \n",
    "    J = 1/m * (np.dot((-y).conj().T, np.log(h))-np.dot((1-y).conj().T,np.log(1-h))) + reg\n",
    "    # 1/m * (-y'*log(h)-(1-y)'*log(1-h)) + regularization\n",
    "    \n",
    "    gr = np.zeros((n,1)) # initiate the gradient regularization part\n",
    "    \n",
    "    for j in range(1,n):\n",
    "        gr[j] = lambda_var/m*theta[j]\n",
    "    \n",
    "    grad = 1/m * np.dot(X.T,(h-y)) + gr # 1/m * X' * (h-y) + gr'\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regularized Logistic Regression\n",
    "\n",
    "In this part, you are given a dataset with data points that are not linearly separable. However, you would still like to use logistic regression to classify the data points.\n",
    "\n",
    "To do so, you introduce more features to use -- in particular, you add polynomial features to our data matrix (similar to polynomial regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros): 0.693147 \n",
      "\n",
      "Expected cost (approx): 0.693\n",
      "\n",
      "Gradient at initial theta (zeros) - first five values only:\n",
      "\n",
      " 0.008475 \n",
      " 0.018788 \n",
      " 0.000078 \n",
      " 0.050345 \n",
      " 0.011501 \n",
      " \n",
      "Expected gradients (approx) - first five values only:\n",
      "\n",
      " 0.0085\n",
      " 0.0188\n",
      " 0.0001\n",
      " 0.0503\n",
      " 0.0115\n",
      "\n",
      "\n",
      "Cost at test theta (with lambda = 10): 3.164509 \n",
      "\n",
      "Expected cost (approx): 3.16\n",
      "\n",
      "Gradient at test theta - first five values only:\n",
      "\n",
      " 0.346045 \n",
      " 0.161352 \n",
      " 0.194796 \n",
      " 0.226863 \n",
      " 0.092186 \n",
      " \n",
      "Expected gradients (approx) - first five values only:\n",
      "\n",
      " 0.3460\n",
      " 0.1614\n",
      " 0.1948\n",
      " 0.2269\n",
      " 0.0922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that mapFeature also adds a column of ones for us, so the intercept\n",
    "# term is handled\n",
    "X = mapFeature(X) # Call the mapFeature function to return a 118x28 matrix of\n",
    "                    # features in X and added polynomial features\n",
    "\n",
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros((X.shape[1], 1)) # initialize theta as zeros as 28x1\n",
    "\n",
    "# Set regularization parameter lambda to 1, lambda_var is used for notation as\n",
    "# lambda has a defined meaning in python\n",
    "lambda_var = 0 # meaning no regularization when this value is used\n",
    "\n",
    "# Compute and display initial cost and gradient for regularized logistic\n",
    "# regression\n",
    "cost, grad = costFunctionReg(initial_theta, X, y, lambda_var)\n",
    "grad = grad.flatten(order='F') # flatten in column major\n",
    "\n",
    "print('Cost at initial theta (zeros): %f \\n' % cost)\n",
    "print('Expected cost (approx): 0.693\\n')\n",
    "print('Gradient at initial theta (zeros) - first five values only:\\n')\n",
    "print(' %f \\n %f \\n %f \\n %f \\n %f \\n ' % (grad[0], grad[1], grad[2], grad[3], grad[4]))    # Maybe needs to be changed to grad[0], grad[1]..    \n",
    "print('Expected gradients (approx) - first five values only:\\n')\n",
    "print(' 0.0085\\n 0.0188\\n 0.0001\\n 0.0503\\n 0.0115\\n')\n",
    "\n",
    "# Compute and display cost and gradient\n",
    "# with all-ones theta and lambda = 10\n",
    "test_theta = np.ones((X.shape[1],1)) # initialize theta as zeros as 28x1\n",
    "cost, grad = costFunctionReg(test_theta, X, y, 10) # call the cost function\n",
    "grad = grad.flatten(order='F') # flatten in column major\n",
    "\n",
    "print('\\nCost at test theta (with lambda = 10): %f \\n' % cost)\n",
    "print('Expected cost (approx): 3.16\\n')\n",
    "print('Gradient at test theta - first five values only:\\n')\n",
    "print(' %f \\n %f \\n %f \\n %f \\n %f \\n ' % (grad[0], grad[1], grad[2], grad[3], grad[4]))    # Maybe needs to be changed to grad[0], grad[1]..    \n",
    "print('Expected gradients (approx) - first five values only:\\n')\n",
    "print(' 0.3460\\n 0.1614\\n 0.1948\\n 0.2269\\n 0.0922\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotDecisionBoundary DOES NOT WORK (Probably just delete it, I included it here if you want to try it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "#from sklearn.datasets.base import load_iris\n",
    "#from sklearn.manifold.t_sne import TSNE\n",
    "#from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "#pos = indices(y, lambda y: y > 0)  # filter the positive results (y = 1)\n",
    "#neg = indices(y, lambda y: y == 0) # filter the negative results (y = 0)\n",
    "\n",
    "#plt.scatter((data[:,0:2])[pos,0], (data[:,0:2])[pos,1], label='Admitted', \n",
    "#            color = 'k', marker = '+') # set plotting parameters \n",
    "#plt.scatter((data[:,0:2])[neg,0], (data[:,0:2])[neg,1], label='Not admitted',\n",
    "#            color = 'y', marker = 'o')  # set plotting parameters (colour=red, \n",
    "                                        # marker=cross)\n",
    "\n",
    "#resolution = 100 # 100x100 background pixels\n",
    "#X2d_xmin, X2d_xmax  = [min(X[:,1]), max(X[:,1])] # determine x-coordinates of boundary\n",
    "\n",
    "#X2d_ymin, X2d_ymax  = [min(y), max(y)] # determine y-coordinates\n",
    "                                                    # of boundary\n",
    "#xx, yy = np.meshgrid(np.linspace(X2d_xmin, X2d_xmax, resolution), np.linspace(X2d_ymin, X2d_ymax, resolution))\n",
    "\n",
    "#background_model = KNeighborsClassifier(n_neighbors=1).fit(X, p) \n",
    "#voronoiBackground = background_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "#voronoiBackground = voronoiBackground.reshape((resolution, resolution))\n",
    "\n",
    "#plot\n",
    "#plt.contourf(xx, yy, voronoiBackground)\n",
    "\n",
    "#plt.xlabel('Microchip Test 1')  # set the x-axis label\n",
    "#plt.ylabel('Microchip Test 2')             # set the y-axis label\n",
    "#plt.legend(['y=1', 'y=0'])\n",
    "#plt.show()                                   # plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Regularization and Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise:\n",
    "In this part, you will get to try different values of lambda and see how regularization affects the decision boundary.\n",
    "\n",
    "Try the following values of lambda (0, 1, 10, 100).\n",
    "\n",
    "How does the decision boundary change when you vary lambda? How does the training set accuracy vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros((X.shape[1], 1)) # initialize theta as zeros\n",
    "\n",
    "# Set regularization parameter lambda to 1 (you should vary this)\n",
    "lambda_var = 1\n",
    "\n",
    "# These functions are created so the opt.fmin_tnc can be ran\n",
    "# Optimise\n",
    "def costReg(theta, X, y, lambda_var):\n",
    "    theta = np.matrix(theta) # transform all the arrays to matrices for compatibility\n",
    "    if theta.shape[0] < theta.shape[1]:\n",
    "        theta = theta.T\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    grad = np.zeros((theta.shape))\n",
    "    reg = 0\n",
    "    ## Your code\n",
    "    \n",
    "    # correct answer\n",
    "    z = np.dot(X,theta) # X * theta\n",
    "    h = logistic.cdf(z) # sigmoid(X*theta)\n",
    "    \n",
    "    n = X.shape[1] # define how many thetas need to be regularized\n",
    "    \n",
    "    for j in range(1,n): # calculate the regularization value\n",
    "        reg = reg + lambda_var/(2*m)*theta[j]**2\n",
    "    \n",
    "    J = 1/m * (np.dot((-y).conj().T, np.log(h))-np.dot((1-y).conj().T,np.log(1-h))) + reg\n",
    "    # 1/m * (-y'*log(h)-(1-y)'*log(1-h)) + regularization\n",
    "    return J\n",
    "\n",
    "def gradientReg(theta, X, y, lambda_var):\n",
    "    theta = np.matrix(theta) # transform all arrays to matrices for compatibility\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "        \n",
    "    if theta.shape[0] < theta.shape[1]:\n",
    "        theta = theta.T\n",
    "    n = X.shape[1] # define how many thetas need to be regularized\n",
    "    z = np.dot(X,theta) # X * theta\n",
    "    h = logistic.cdf(z) # sigmoid(X*theta)\n",
    "    \n",
    "    gr = np.zeros((n,1))\n",
    "    gr[0] = 0\n",
    "    \n",
    "    for j in range(1,n):\n",
    "        gr[j] = lambda_var/m*theta[j]\n",
    "    \n",
    "    grad = 1/m * np.dot(X.T,(h-y)) + gr # 1/m * X' * (h-y) + gr'\n",
    "    return grad\n",
    "    \n",
    "result2 = opt.fmin_tnc(func=costReg, x0=initial_theta, fprime=gradientReg, args=(X, y,lambda_var)) # function to optimise\n",
    "\n",
    "theta = np.array((result2[0])) # put the updated optimised thetas in theta\n",
    "theta = theta.reshape(len(theta),1) # make sure theta is a 28x1 array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy your predict file from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some useful values\n",
    "m = len(y) # number of training examples\n",
    "\n",
    "p = np.zeros((m,1)) # initialize the p array with zeros\n",
    "\n",
    "def predict(theta, X):        # define function to reference later\n",
    "    ## Your code\n",
    "    \n",
    "    # correct answer\n",
    "    z = np.dot(X,theta) # X*theta\n",
    "    h = logistic.cdf(z) # sigmoid(z)\n",
    "    \n",
    "    for i in range(m):\n",
    "        if h[i] >= 0.5: # threshold is set at 0.5\n",
    "            p[i] = 1 # only positive predictions are changed to 1\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute accuracy on our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 83.050847 %\n"
     ]
    }
   ],
   "source": [
    "p = predict(theta,X)\n",
    "\n",
    "def accuracy_score_new(y_pred, y_true):\n",
    "    matched = 0 # initialize number of correct answers\n",
    "    for y_p, y_t in zip(y_pred, y_true): # loop over all predicted and real values\n",
    "        if y_t in y_p:\n",
    "            matched = matched + 1 # add 1 to for each correctly predicted answer\n",
    "\n",
    "    return (matched / len(y_true)) * 100 # returns the number of correct answers divided \n",
    "                                            # by number of total predictions * 100\n",
    "\n",
    "accuracy = accuracy_score_new(p,y)\n",
    "\n",
    "# of right predictions/accuracy\n",
    "print('Train Accuracy: %f' % accuracy, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
